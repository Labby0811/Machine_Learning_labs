{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Linear models: Support Vector Machines (SVM)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this notebook we are going to explore linear models and Support Vector Machines (SVM in short).\n",
                "\n",
                "Let's first import the required packages."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- put here your ID number (numero di matricola)\n",
                "ID_number = \n",
                "\n",
                "from sklearn import datasets, preprocessing, linear_model, svm\n",
                "%matplotlib inline\n",
                "import matplotlib.pyplot as plt\n",
                "from matplotlib.lines import Line2D\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## SVM for linearly separable data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's start by creating a simple linearly separable dataset for binary classification, where the instance space is $\\mathcal{X} =\\mathbb{R}^2$ (so that we can visualize it). Just to make things easier, we are going to rescale it too."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "X, y = datasets.make_blobs(n_samples = 500, centers = 2, n_features = 2, random_state=ID_number)\n",
                "\n",
                "scaler = preprocessing.StandardScaler()\n",
                "scaler.fit(X)\n",
                "X = scaler.transform(X)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The following code plots the dataset, it is useful for later parts too."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "plt.title(\"Plot of dataset\")\n",
                "plt.scatter(X[:, 0], X[:, 1], c=y);"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let's run the perceptron, using $\\texttt{linear\\_model.Perceptron(...)}$ from sklearn. We fix the number of iterations to 100 so that it runs quickly (since we have a pretty simple to classifiy and linearly separable dataset) , and $\\texttt{random\\_state=10}$.\n",
                "\n",
                "What do we expect in terms of training error? "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Create a perceptron classifier\n",
                "model_perceptron_1 = linear_model.Perceptron(max_iter=100, random_state = 10)\n",
                "\n",
                "# -- Train the model on all data\n",
                "model_perceptron_1.fit(X, y)\n",
                "\n",
                "# -- Get the training error as 1 - score()\n",
                "training_error = 1 - model_perceptron_1.score(X,y)\n",
                "\n",
                "# -- Print the training error\n",
                "print(\"Training error: \", training_error)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The following code plots the *decision boundary* of a model and the training set. It is useful for later parts too."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- model_perceptron should be already trained\n",
                "def plot_perceptron_boundaries(X, y, model_perceptron):\n",
                "\n",
                "    plt.scatter(X[:, 0], X[:, 1], c=y, s=30)\n",
                "    ax = plt.gca()\n",
                "    plt.title(\"Plot of perceptron decision boundary\")\n",
                "    xlim = ax.get_xlim()\n",
                "    ylim = ax.get_ylim()\n",
                "    # -- create grid to evaluate model\n",
                "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
                "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
                "    YY, XX = np.meshgrid(yy, xx)\n",
                "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
                "    Z = model_perceptron.decision_function(xy).reshape(XX.shape)\n",
                "    # -- plot decision boundary and margins\n",
                "    ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1, linestyles=['-']);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- let's print the decision boundaries of model_perceptron_1\n",
                "plot_perceptron_boundaries(X, y, model_perceptron_1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If we change the value of $\\texttt{random\\_state}$ in the perceptron, it will start from a different model. \n",
                "\n",
                "Let's run the perceptron with different $\\texttt{random\\_state}$. How will the solution compare to the above?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Create a perceptron classifier\n",
                "model_perceptron_2 = linear_model.Perceptron(max_iter=100, random_state = 12)\n",
                "\n",
                "# -- Training the model\n",
                "model_perceptron_2.fit(X, y)\n",
                "\n",
                "# -- Get the training error as 1 - score()\n",
                "training_error = 1 - model_perceptron_2.score(X,y)\n",
                "\n",
                "# -- Print the training error\n",
                "print(\"Training error: \", training_error)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "What about the decision boundary? Let's plot it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's print the decision boundaries of model_perceptron_2\n",
                "plot_perceptron_boundaries(X, y, model_perceptron_2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Which model is better? \n",
                "\n",
                "Is any of these the *best* choice?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, let's run the hard-SVM on the same data. To obtain (an almost) hard-SVM in sklearn, we can use $\\texttt{svm.SVC(...)}$ with a very high value of the parameter $C$.\n",
                "\n",
                "Note: the $C$ parameter used by $\\texttt{svm.SVC(...)}$ method in sklearn is approximately equal to $1 / \\lambda$, with respect to our use and definition of $\\lambda$. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Creating a SVM model\n",
                "model_svm_1 = svm.SVC(kernel=\"linear\", C=1e8)\n",
                "\n",
                "# -- Training the model\n",
                "model_svm_1.fit(X, y)\n",
                "\n",
                "# -- Get the training error as 1 - score()\n",
                "training_error = 1 - model_svm_1.score(X,y)\n",
                "\n",
                "# -- Print the training error\n",
                "print(\"Training error: \", training_error)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Plot the SVM decision boundary."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Code for plotting the decision boundary for svm\n",
                "# -- svm_models must be a list of svm models\n",
                "def plot_svm_boundaries(X, y, svm_models, show_sv=False, show_margin=False):\n",
                "\n",
                "    plt.scatter(X[:, 0], X[:, 1], c=y, s=30)\n",
                "    ax = plt.gca()\n",
                "    plt.title(\"Plot of SVM decision boundary\")\n",
                "    xlim = ax.get_xlim()\n",
                "    ylim = ax.get_ylim()\n",
                "    # create grid to evaluate model\n",
                "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
                "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
                "    YY, XX = np.meshgrid(yy, xx)\n",
                "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
                "\n",
                "    palette = [f'C{i}' for i in range(len(svm_models))]\n",
                "    handles = []\n",
                "\n",
                "    for idx, svm in enumerate(svm_models):\n",
                "    \n",
                "        Z = svm.decision_function(xy).reshape(XX.shape)\n",
                "        # plot decision boundary and margins\n",
                "        if show_margin:\n",
                "            ax.contour(XX, YY, Z, colors = palette[idx], levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"])\n",
                "        else:\n",
                "            ax.contour(XX, YY, Z, colors = palette[idx], levels=[0], alpha=1, linestyles=['-']);\n",
                "        handles.append(Line2D([0], [0], label=f'SVM {idx+1}', color=palette[idx]))\n",
                "        if show_sv:\n",
                "            plt.scatter(svm.support_vectors_[:, 0], svm.support_vectors_[:, 1], color = palette[idx], marker='s', alpha=.85)\n",
                "\n",
                "    ax.legend(handles = handles, loc = 'lower left')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_svm_boundaries(X, y, [model_svm_1])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's see what the support vectors are. They are defined in attribute $\\texttt{support\\_vectors\\_}$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- print the support vectors\n",
                "print('Support Vectors:\\n', model_svm_1.support_vectors_)\n",
                "\n",
                "print('---')\n",
                "\n",
                "# -- print dual coefficients\n",
                "print('Dual Coefficients of Support Vectors:\\n', model_svm_1.dual_coef_)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's see what happens moving one support vector. We first obtain the indices of the support vectors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's actually plot the support vectors\n",
                "plot_svm_boundaries(X, y, [model_svm_1], show_sv = True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "Now, let's try to play a bit with the support vectors, in order to see how the svm model is going to behave.\n",
                "\n",
                "For instance, let's try to move one of the above support vectors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- print the indices of support vectors (attribute support)\n",
                "print(model_svm_1.support_)\n",
                "# -- for example, let's move the point indexed by 321, that is\n",
                "X[321]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let's move one support vector closer to the points in the same class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- let's copy the data and move one support vector close to the points in the same class\n",
                "X1 = X.copy()\n",
                "# the suppport vector indexed by 321 goes from x coordinate ~ -0.2 x coordinate -1\n",
                "X1[321, 0] = -1\n",
                "\n",
                "# -- let's plot the new dataset\n",
                "plt.title(\"Plot of dataset\")\n",
                "plt.scatter(X1[:, 0], X1[:, 1], c=y)\n",
                "\n",
                "# -- see the movement of the support vector (then comment to see the whole actual dataset)\n",
                "plt.scatter(X[321, 0], X[321, 1], color = 'red', edgecolor='k')\n",
                "plt.scatter(X1[321, 0], X1[321, 1], color = 'red', edgecolor='k')\n",
                "plt.annotate('', xytext=(X[321, 0], X[321, 1]), xy=(X1[321, 0], X1[321, 1]),\n",
                "            arrowprops=dict(facecolor='red', shrink=0.07, width=2.5));"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's run the SVM on the new data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Creating a SVM model\n",
                "model_svm_2 = svm.SVC(kernel=\"linear\", C=1e8)\n",
                "\n",
                "# -- Training the model\n",
                "model_svm_2.fit(X1, y)\n",
                "\n",
                "# -- Get the training error as 1 - score()\n",
                "training_error = 1 - model_svm_2.score(X1,y)\n",
                "\n",
                "# -- Print the training error\n",
                "print(\"Training error: \", training_error)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Plot the SVM decision boundary and the previous decision boundary."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Plot boundaries for different SVMs\n",
                "plot_svm_boundaries(X1, y, [model_svm_1, model_svm_2])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Let's see now what the support vectors are\n",
                "print('Support Vectors of model 1:\\n', model_svm_1.support_vectors_)\n",
                "print('---')\n",
                "print('Support Vectors of model 2:\\n', model_svm_2.support_vectors_)\n",
                "print('---')\n",
                "# -- Let's print the dual coefficients as well\n",
                "print('Dual Coefficients of Support Vectors of model 1:\\n', model_svm_1.dual_coef_)\n",
                "print('---')\n",
                "print('Dual Coefficients of Support Vectors of model 2:\\n', model_svm_2.dual_coef_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Plot svm boundaries for comparison with support vectors highlighted\n",
                "plot_svm_boundaries(X1, y, [model_svm_1, model_svm_2], show_sv = True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "Now let's move the same support vector to the right, i.e., closer to the points in the other class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- let's copy the original data and move one support vector close to the points in the other class\n",
                "X2 = X.copy()\n",
                "X2[321, 0] = 0.2\n",
                "\n",
                "# -- let's plot the new dataset\n",
                "plt.title(\"Plot of dataset\")\n",
                "plt.scatter(X2[:, 0], X2[:, 1], c=y)\n",
                "\n",
                "# -- see the movement of the support vector (then comment to see the whole actual dataset)\n",
                "plt.scatter(X[321, 0], X[321, 1], color = 'red', edgecolor='k')\n",
                "plt.scatter(X2[321, 0], X2[321, 1], color = 'red', edgecolor='k')\n",
                "plt.annotate('', xytext=(X[321, 0], X[321, 1]), xy=(X2[321, 0], X2[321, 1]),\n",
                "            arrowprops=dict(facecolor='red', shrink=0.12, width=2.5, headwidth=10.0));"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's run the SVM on the new data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Creating a SVM model\n",
                "model_svm_3 = svm.SVC(kernel=\"linear\", C=1e8)\n",
                "\n",
                "# -- Training the model\n",
                "model_svm_3.fit(X2, y)\n",
                "\n",
                "# -- Get the training error as 1 - score()\n",
                "training_error = 1 - model_svm_3.score(X2,y)\n",
                "\n",
                "# -- Print the training error\n",
                "print(\"Training error: \", training_error)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Plot svm boundaries\n",
                "plot_svm_boundaries(X2, y, [model_svm_1, model_svm_2, model_svm_3])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's plot the new decision boundary, and the old ones too."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Let's see now what the support vectors are\n",
                "print('Support Vectors of model 1:\\n', model_svm_1.support_vectors_)\n",
                "print('---')\n",
                "print('Support Vectors of model 2:\\n', model_svm_2.support_vectors_)\n",
                "print('---')\n",
                "print('Support Vectors of model 3:\\n', model_svm_3.support_vectors_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Let's print the dual coefficients as well\n",
                "print('Dual Coefficients of Support Vectors of model 1:\\n', model_svm_1.dual_coef_)\n",
                "print('---')\n",
                "print('Dual Coefficients of Support Vectors of model 2:\\n', model_svm_2.dual_coef_)\n",
                "print('---')\n",
                "print('Dual Coefficients of Support Vectors of model 3:\\n', model_svm_3.dual_coef_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Plot svm boundaries with support vectors for comparison\n",
                "plot_svm_boundaries(X1, y, [model_svm_1, model_svm_2, model_svm_3], show_sv = True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## SVM for non-linearly separable data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's make a dataset that is not linearly separble, and let's plot it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "X_nls, y_nls = datasets.make_blobs(n_samples = 500, centers = 2, n_features = 2, random_state = ID_number)\n",
                "\n",
                "scaler.fit(X_nls)\n",
                "X_nls = scaler.transform(X_nls)\n",
                "\n",
                "# -- let's manually create a nls dataset\n",
                "a = np.array([[0.3, 2]])\n",
                "b = np.array([0])\n",
                "X_nls = np.concatenate((X_nls, a))\n",
                "y_nls = np.concatenate((y_nls, b))\n",
                "a = np.array([[0.1, -1.5]])\n",
                "b = np.array([0])\n",
                "X_nls = np.concatenate((X_nls, a))\n",
                "y_nls = np.concatenate((y_nls, b))\n",
                "\n",
                "a = np.array([[0, 0.1]])\n",
                "b = np.array([1])\n",
                "X_nls = np.concatenate((X_nls, a))\n",
                "y_nls = np.concatenate((y_nls, b))\n",
                "\n",
                "plt.title(\"Plot of dataset\")\n",
                "plt.scatter(X_nls[:, 0], X_nls[:, 1], c=y_nls);"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's try to learn a hard-SVM. It means that the parameter C, which is approximately equal to $1/\\lambda$ with $\\lambda$ as in our slides."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Creating a HARD SVM model\n",
                "model_hard_svm_1 = svm.SVC(kernel=\"linear\", C=1e8)\n",
                "\n",
                "# -- Training the model\n",
                "model_hard_svm_1.fit(X_nls, y_nls)\n",
                "\n",
                "# -- Get the training error as 1 - score()\n",
                "training_error = 1 - model_hard_svm_1.score(X_nls, y_nls)\n",
                "\n",
                "# -- Print the training error\n",
                "print(\"Training error: \", training_error)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The following code plots the decision boundary, as well as the margin."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Plot of hard SVM decision boundary\n",
                "plot_svm_boundaries(X_nls, y_nls, [model_hard_svm_1], show_sv=True, show_margin=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Let's see now what the support vectors and dual coefficients are\n",
                "print('Support Vectors of model 1:\\n', model_hard_svm_1.support_vectors_)\n",
                "print('---')\n",
                "print('Dual Coefficients of Support Vectors of model 1:\\n', model_hard_svm_1.dual_coef_)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's try with a smaller value of C ($10^4$), that corresponds to larger value of $\\lambda$.\n",
                "\n",
                "What do you expect?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Creating a soft SVM model\n",
                "model_soft_svm_2 = svm.SVC(kernel=\"linear\", C=1e4)\n",
                "\n",
                "# -- Training the model\n",
                "model_soft_svm_2.fit(X_nls, y_nls)\n",
                "\n",
                "# -- Get the training error as 1 - score()\n",
                "training_error = 1 - model_soft_svm_2.score(X_nls, y_nls)\n",
                "\n",
                "# -- Print the training error\n",
                "print(\"Training error: \", training_error)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "What about the decision boundary and the margin?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Plot of soft SVM decision boundary\n",
                "plot_svm_boundaries(X_nls, y_nls, [model_soft_svm_2], show_sv=True, show_margin=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Let's see now what the support vectors and dual coefficients are\n",
                "print('Support Vectors of model 1:\\n', model_hard_svm_1.support_vectors_)\n",
                "print('---')\n",
                "print('Support Vectors of model 2:\\n', model_soft_svm_2.support_vectors_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Dual Coefficients of Support Vectors for model 1:\\n', model_hard_svm_1.dual_coef_)\n",
                "print('---')\n",
                "print('Dual Coefficients of Support Vectors for model 2:\\n', model_soft_svm_2.dual_coef_)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's repeat everything for an even smaller C, i.e., C = 100"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Creating a soft SVM model\n",
                "model_soft_svm_3 = svm.SVC(kernel=\"linear\", C=100)\n",
                "\n",
                "# -- Training the model\n",
                "model_soft_svm_3.fit(X_nls, y_nls)\n",
                "\n",
                "# -- Get the training error as 1 - score()\n",
                "training_error = 1 - model_soft_svm_3.score(X_nls, y_nls)\n",
                "\n",
                "# -- Print the training error (seems to be exactly the same as before)\n",
                "print(\"Training error: \", training_error)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Plot of soft SVM decision boundary\n",
                "plot_svm_boundaries(X_nls, y_nls, [model_soft_svm_3], show_sv=True, show_margin=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "What about setting C = 1?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Creating a soft SVM model \n",
                "model_soft_svm_4 = svm.SVC(kernel=\"linear\", C=1)\n",
                "\n",
                "# -- Training the model\n",
                "model_soft_svm_4.fit(X_nls, y_nls)\n",
                "\n",
                "# -- Get the training error as 1 - score()\n",
                "training_error = 1 - model_soft_svm_4.score(X_nls, y_nls)\n",
                "\n",
                "# -- Print the training error (corresponds to 3 misclassified points)\n",
                "print(\"Training error: \", training_error)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Plot of soft SVM decision boundary\n",
                "plot_svm_boundaries(X_nls, y_nls, [model_soft_svm_4], show_sv=True, show_margin=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's see what are the support vectors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- Let's see now what the support vectors and dual coefficients are\n",
                "print('Support Vectors of model 4:\\n\\n', model_soft_svm_4.support_vectors_)\n",
                "print('---')\n",
                "print('Dual Coefficients of Support Vectors for model 4:\\n\\n', model_soft_svm_4.dual_coef_)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Comparison with Perceptron\n",
                "\n",
                "Just for comparison, let's run the perceptron on the same dataset with various initial random states"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's plot the decision boundary."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "model_perceptron_1 = linear_model.Perceptron(max_iter=100, random_state = 143)\n",
                "model_perceptron_1.fit(X_nls, y_nls)\n",
                "training_error = 1 - model_perceptron_1.score(X_nls, y_nls)\n",
                "print(\"Training error: \", training_error)\n",
                "# -- plot perceptron boundaries\n",
                "plot_perceptron_boundaries(X_nls, y_nls, model_perceptron_1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_perceptron_2 = linear_model.Perceptron(max_iter=100, random_state = 10)\n",
                "model_perceptron_2.fit(X_nls, y_nls)\n",
                "training_error = 1 - model_perceptron_2.score(X_nls, y_nls)\n",
                "print(\"Training error: \", training_error)\n",
                "# -- plot perceptron boundaries\n",
                "plot_perceptron_boundaries(X_nls, y_nls, model_perceptron_2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_perceptron_3 = linear_model.Perceptron(max_iter=100, random_state = 24)\n",
                "model_perceptron_3.fit(X_nls, y_nls)\n",
                "training_error = 1 - model_perceptron_3.score(X_nls, y_nls)\n",
                "print(\"Training error: \", training_error)\n",
                "# -- plot perceptron boundaries\n",
                "plot_perceptron_boundaries(X_nls, y_nls, model_perceptron_3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### K-Fold Cross Validation\n",
                "\n",
                "Now, let's try to select the best SVM model using $k$-fold cross validation, with respect to the parameter $C$.\n",
                "\n",
                "More specifically, let's fix a non-linearly separable dataset. You need to perform train-validation-test split, fix a grid for the hyperparameter $C$, and perform model selection by running $k$-fold cross validations (let's say $k = 5$, but you can try to change).\n",
                "\n",
                "At the end, we would like to collect the best models, in terms of generalization error, achieved by you. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- generate the dataset\n",
                "X, Y = datasets.make_blobs(n_samples = 1000, centers = 2, n_features = 2, \n",
                "                            center_box=(-7.5, 7.5), random_state = 37, cluster_std = 2.8)\n",
                "\n",
                "# -- divide in: train_and_val = 5/6, test = 1/6\n",
                "\n",
                "# -- TO COMPLETE (from now on)\n",
                "# -- perform train-val-test split\n",
                "# -- fix k of k-fold = 5 (for example)\n",
                "\n",
                "m = \n",
                "m_train_and_val = \n",
                "m_test = \n",
                "\n",
                "# -- print sizes\n",
                "print(\"Amount of data for training and validation:\", m_train_and_val)\n",
                "print(\"Amount of data for test:\", m_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Comparison with Perceptron\n",
                "\n",
                "Finally, let's compare the best model obtained above with some perceptrons. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- TO COMPLETE\n",
                "perceptron_1 = "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- TO COMPLETE: compute generalization error"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- you may try other perceptron models with different seeds"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}