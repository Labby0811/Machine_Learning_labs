{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# First part: Comparison of classifiers on simulated data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from sklearn.datasets import make_moons, make_circles, make_classification, make_blobs\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import Perceptron\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.neural_network import MLPClassifier #Multilayer perceptron classifier\n",
                "from matplotlib.colors import ListedColormap"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The following are two useful functions for plotting a dataset (only training, or all data split into training and test) and the decision boundary of a model and the data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "def plot_dataset(X_train, y_train, X_test=None, y_test=None):\n",
                "    # -- function that plots the datapoints\n",
                "    h = 0.02 # -- h is the step length\n",
                "    x_min, x_max = X_train[:, 0].min() - 0.5, X_train[:, 0].max() + 0.5\n",
                "    y_min, y_max = X_train[:, 1].min() - 0.5, X_train[:, 1].max() + 0.5\n",
                "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
                "\n",
                "    # -- just plot the dataset first\n",
                "    cm = plt.cm.RdBu\n",
                "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
                "    ax = plt.subplot(1,1,1)\n",
                "    ax.set_title(\"Input data\")\n",
                "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
                "\n",
                "    if X_test is not None and y_test is not None:\n",
                "        # -- Plot the testing points\n",
                "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.2, edgecolors=\"k\")\n",
                "\n",
                "    ax.set_xlim(xx.min(), xx.max())\n",
                "    ax.set_ylim(yy.min(), yy.max())\n",
                "    ax.set_xticks(())\n",
                "    ax.set_yticks(())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "def plot_model(input_model, X_train, y_train, X_test, y_test):\n",
                "    # -- function that plots the datapoints and decision boundaries of input_model\n",
                "    h = 0.02\n",
                "    x_min, x_max = X_train[:, 0].min() - 0.5, X_train[:, 0].max() + 0.5\n",
                "    y_min, y_max = X_train[:, 1].min() - 0.5, X_train[:, 1].max() + 0.5\n",
                "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
                "\n",
                "    # -- just plot the dataset first\n",
                "    cm = plt.cm.RdBu\n",
                "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
                "    ax = plt.subplot(1, 1, 1)\n",
                "\n",
                "    ax.set_title(\"Model decision boundary\")\n",
                "    # -- Plot the decision boundary. For that, we will assign a color to each\n",
                "    # -- point in the mesh [x_min, x_max] x [y_min, y_max].\n",
                "    if hasattr(input_model, \"decision_function\"):\n",
                "        Z = input_model.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
                "    else:\n",
                "        Z = input_model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
                "\n",
                "    # -- Put the result into a color plot\n",
                "    Z = Z.reshape(xx.shape)\n",
                "    ax.contourf(xx, yy, Z, cmap=cm, alpha = 0.8)\n",
                "\n",
                "    # -- Plot the training points\n",
                "    ax.scatter(X_train[:, 0], X_train[:, 1], c = y_train, cmap = cm_bright, edgecolors = \"k\")\n",
                "    # -- Plot the testing points\n",
                "    ax.scatter(X_test[:, 0], X_test[:, 1], c = y_test, cmap = cm_bright, edgecolors = \"k\", alpha = 0.2)\n",
                "\n",
                "    ax.set_xlim(xx.min(), xx.max())\n",
                "    ax.set_ylim(yy.min(), yy.max())\n",
                "    ax.set_xticks(())\n",
                "    ax.set_yticks(())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's generate an almost linearly separable dataset and run the perceptron first, then SVM, then a NN with default parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- generate a random n-classification dataset\n",
                "X, y = make_classification(\n",
                "    n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1\n",
                ")\n",
                "\n",
                "# -- add noise to points exploiting a uniform distribution\n",
                "# -- the aim is to get closer to a non-linearly separable dataset\n",
                "rng = np.random.RandomState(2)\n",
                "X += 2 * rng.uniform(size = X.shape)\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's plot the training dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "plot_dataset(X_train_scaled, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's now print all data (i.e., train and and test). The points in the test set are the most transparent that will be displayed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "plot_dataset(X_train_scaled, y_train, X_test_scaled, y_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let's learn a perceptron, plot its decision boundary, and print the train error and the test error."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "perceptron = Perceptron(random_state = 11)\n",
                "perceptron.fit(X_train_scaled, y_train)\n",
                "\n",
                "plot_model(perceptron, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error:, {(1.0 - perceptron.score(X_train_scaled, y_train)):.5f}')\n",
                "\n",
                "print(f'Test error:, {(1.0 - perceptron.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's do the same for SVM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "svm = SVC(kernel = \"linear\", C = 1)\n",
                "svm.fit(X_train_scaled, y_train)\n",
                "\n",
                "plot_model(svm, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - svm.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - svm.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's try with a NN."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# -- one hidden layer with size= 100, activation function = ReLU (see documentation)\n",
                "mlp = MLPClassifier(max_iter = 1000)\n",
                "mlp.fit(X_train_scaled, y_train)\n",
                "\n",
                "plot_model(mlp, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - mlp.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - mlp.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "Let's try now with some more complex dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "X, y = make_moons(noise = 0.3, random_state = 0)\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's plot the training data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "plot_dataset(X_train_scaled, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's plot all the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "plot_dataset(X_train_scaled, y_train, X_test_scaled, y_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's run the perceptron."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "perceptron = Perceptron(random_state = 11)\n",
                "perceptron.fit(X_train_scaled, y_train)\n",
                "\n",
                "plot_model(perceptron, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - perceptron.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - perceptron.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's run the SVM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "svm = SVC(kernel = \"linear\")\n",
                "svm.fit(X_train, y_train)\n",
                "\n",
                "plot_model(svm, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - svm.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - svm.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's try the NN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "mlp = MLPClassifier(max_iter = 1500)\n",
                "# -- Note that with max_iter = 1000 the model is not converging. (see 'tol' parameter). Try to re-train with max_iter = 1500\n",
                "mlp.fit(X_train_scaled, y_train)\n",
                "\n",
                "plot_model(mlp, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - mlp.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - mlp.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "Another interesting dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "X, y = make_circles(noise = 0.2, factor = 0.5, random_state = 1)\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=42)\n",
                "\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's plot the training data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "plot_dataset(X_train_scaled, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's plot all the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "plot_dataset(X_train_scaled, y_train, X_test_scaled, y_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's run the perceptron"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "perceptron = Perceptron(random_state = 11)\n",
                "perceptron.fit(X_train_scaled, y_train)\n",
                "\n",
                "plot_model(perceptron, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - perceptron.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - perceptron.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's run the SVM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "svm = SVC(kernel = \"linear\")\n",
                "svm.fit(X_train, y_train)\n",
                "\n",
                "plot_model(svm, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - svm.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - svm.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's run the NN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "mlp = MLPClassifier(max_iter = 1000)\n",
                "mlp.fit(X_train_scaled, y_train)\n",
                "\n",
                "plot_model(mlp, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - mlp.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - mlp.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "Let's now consider the blobs dataset considered in the last Lab."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- make_blobs dataset\n",
                "\n",
                "# -- generate the dataset\n",
                "X, y = make_blobs(n_samples = 1000, centers = 2, n_features = 2, center_box=(-7.5, 7.5), random_state = 37, cluster_std = 2.8)\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
                "\n",
                "# -- scale data\n",
                "scaler = StandardScaler()\n",
                "scaler.fit(X_train)\n",
                "X_train_scaled = scaler.transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's plot all the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_dataset(X_train_scaled, y_train, X_test_scaled, y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- perceptron\n",
                "perceptron = Perceptron(random_state = 11)\n",
                "perceptron.fit(X_train_scaled, y_train)\n",
                "\n",
                "plot_model(perceptron, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - perceptron.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - perceptron.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- svm\n",
                "svm = SVC(kernel = \"linear\")\n",
                "svm.fit(X_train, y_train)\n",
                "\n",
                "plot_model(svm, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - svm.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - svm.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- NN (mlp)\n",
                "mlp = MLPClassifier(max_iter = 1000)\n",
                "mlp.fit(X_train_scaled, y_train)\n",
                "\n",
                "plot_model(mlp, X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "\n",
                "print(f'Training error: {(1.0 - mlp.score(X_train_scaled, y_train)):.5f}')\n",
                "print(f'Test error: {(1.0 - mlp.score(X_test_scaled, y_test)):.5f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Second part: Regression on House Pricing Dataset\n",
                "We consider a reduced version of a dataset containing house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
                "\n",
                "https://www.kaggle.com/harlfoxem/housesalesprediction\n",
                "\n",
                "For each house we know 18 house features (e.g., number of bedrooms, number of bathrooms, etc.) plus its price, that is what we would like to predict."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- put here your ID_Number  (numero di matricola)\n",
                "numero_di_matricola = 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#import all packages needed\n",
                "# %matplotlib inline\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# -- avoid convergence warnings from sklearn library\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Load the data, remove data samples/points with missing values (NaN) and take a look at them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- load the dataset\n",
                "df = pd.read_csv('kc_house_data.csv', sep = ',')\n",
                "# -- remove the data samples with missing values (NaN)\n",
                "df = df.dropna()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- print the column names and the first 5 rows of the dataframe\n",
                "print(df.columns)\n",
                "print('\\n')\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Extract input and output data. We want to predict the price by using features other than id as input."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Data = df.values\n",
                "# -- m = number of input samples\n",
                "m = Data.shape[0]\n",
                "print(\"Amount of data:\",m)\n",
                "Y = Data[:m, 2]\n",
                "X = Data[:m, 3:]\n",
                "\n",
                "# -- print shapes\n",
                "print(\"X shape: \", X.shape)\n",
                "print(\"Y shape: \", Y.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Pre-Processing\n",
                "\n",
                "We split the data into 3 parts: one will be used for training and choosing the parameters, one for choosing among different models, and one for testing. The part for training and choosing the parameters will consist of $2/3$ of all samples, the one for choosing among different models will consist of $1/6$ of all samples, while the other part consists of the remaining $1/6$-th of all samples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Split data into train (2/3 of samples), validation (1/6 of samples), and test data (the rest)\n",
                "m_train = int(2/3*m)\n",
                "m_val = int((m-m_train)/2)\n",
                "m_test = m - m_train - m_val\n",
                "print(\"Amount of data for training and deciding parameters:\", m_train)\n",
                "print(\"Amount of data for validation (choosing among different models):\", m_val)\n",
                "print(\"Amount of data for test:\", m_test)\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X_train_and_val, X_test, Y_train_and_val, Y_test = train_test_split(X, Y, test_size = m_test/m, random_state = numero_di_matricola)\n",
                "X_train, X_val, Y_train, Y_val = train_test_split(X_train_and_val, Y_train_and_val,\n",
                "                                                  test_size = m_val/(m_train + m_val), random_state = numero_di_matricola)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's standardize the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Data pre-processing\n",
                "from sklearn import preprocessing\n",
                "scaler = preprocessing.StandardScaler().fit(X_train)\n",
                "X_train_scaled = scaler.transform(X_train)\n",
                "X_val_scaled = scaler.transform(X_val)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "X_train_and_val_scaled = scaler.transform(X_train_and_val)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Neural Networks\n",
                "Let's start by learning a simple neural network with 1 hidden node.\n",
                "Note: we are going to use the input parameter solver='lbfgs' and random_state=numero_di_matricola to fix the random seed (so results are reproducible)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We hereby define a function to train an MLPRegressor on the (already scaled) training data and (optionally) print its parameters at the end of the training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- look at kwargs** in Python"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In the function definition, a special syntax called `**kwargs` is used to pass a keyworded, variable-length argument list into the configuration settings of the `MLPRegressor` model. This syntax enables you to provide flexible and customizable parameters for the model. \n",
                "\n",
                "These keyword arguments allow you to specify various settings such as:\n",
                "- **`hidden_layer_sizes`**, to define the number and size of hidden layers (e.g., `(1,)` for a single hidden layer with one neuron).\n",
                "- **`solver`** (e.g., `'lbfgs'`).\n",
                "- **`random_state`**\n",
                "\n",
                "If you're unfamiliar with this syntax, refer to Python's documentation on `kwargs` for more details.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.neural_network import MLPRegressor\n",
                "\n",
                "def train_model(X_train, Y_train, X_val, Y_val, print_weights = True, **params):\n",
                "\n",
                "    mlp_model = MLPRegressor(**params)\n",
                "    mlp_model.fit(X_train, Y_train)\n",
                "\n",
                "    # -- let's print the error (1 - R^2) on training data\n",
                "    print(f'Training error: {(1.0 - mlp_model.score(X_train, Y_train)):.5f}')\n",
                "    # -- let's print the error (1 - R^2) on validation data\n",
                "    print(f'Validation error: {(1.0 - mlp_model.score(X_val, Y_val)):.5f}')\n",
                "\n",
                "    if print_weights:\n",
                "\n",
                "        weights = mlp_model.coefs_\n",
                "        biases = mlp_model.intercepts_\n",
                "\n",
                "        # -- let's print the coefficients of the model for the input nodes (but not the bias)\n",
                "        print('\\n--- Weights of NN ---')\n",
                "\n",
                "        for i_layer, (w, b) in enumerate(zip(weights, biases)):\n",
                "            print(f'\\n# Layer {i_layer+1}')\n",
                "            print(f'--- Weights, with shape {w.shape} ---')\n",
                "            for i in range(w.shape[0]):\n",
                "                for j in range(w.shape[1]):\n",
                "                    print(f'w_({i+1}, {j+1})^({i_layer+1}): {w[i][j]:.3f}')\n",
                "\n",
                "            print(f'--- Biases, with shape {b.shape} ---')\n",
                "            for i in range(b.shape[0]):\n",
                "                print(f'b_{i+1}: {b[i]:.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's define the model\n",
                "# -- Look how to hidden_layer_sizes in the documentation\n",
                "params = {'hidden_layer_sizes': (1, ),\n",
                "          'solver' : 'lbfgs',\n",
                "          'random_state' : numero_di_matricola}\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, **params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Neural Networks vs Linear Models\n",
                "\n",
                "Let's learn a linear model on the same data and compare the results with the simple NN above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn import linear_model\n",
                "\n",
                "LR = linear_model.LinearRegression()\n",
                "\n",
                "LR.fit(X_train_scaled, Y_train)\n",
                "\n",
                "# -- let's print the error (1 - R^2) on training data\n",
                "print(f'Training error: {(1.0 - LR.score(X_train_scaled, Y_train)):.5f}')\n",
                "# -- let's print the error (1 - R^2) on validation data\n",
                "print(f'Validation error: {(1.0 - LR.score(X_val_scaled, Y_val)):.5f}')\n",
                "\n",
                "print(f'\\n--- Weights, with shape {LR.coef_.shape} ---\\n{LR.coef_}')\n",
                "print(f'\\n--- Bias --- \\n{LR.intercept_}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Is there a way to make a NN network learn a linear model?\n",
                "\n",
                "Let's first check what is the activation function used by MLPRegressor..."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's write the code to learn a linear model with NN: how?\n",
                "params = {'hidden_layer_sizes': (1, ),\n",
                "          'solver' : 'lbfgs',\n",
                "          'random_state' : numero_di_matricola,\n",
                "          'activation' : 'identity'\n",
                "         }\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, **params)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- Example of handmade computations: with null input vector:\n",
                "# -- linear model output = bias ~ 536.831,9203\n",
                "# -- NN: w_(1, 1)^(2) * b_1 + b_2 ~ 536.829,396\n",
                "# -- why the above tiny difference? Because of l2 default regularization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note that there is an $\\ell_2$ regularization term in MLPRegressor. What about making it smaller?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- you can try to change alpha (e.g., huge value to see the model is forcing null vector w)\n",
                "params = {'hidden_layer_sizes': (1, ),\n",
                "          'solver' : 'lbfgs',\n",
                "          'random_state' : numero_di_matricola,\n",
                "          'activation' : 'identity',\n",
                "          'alpha' : 1e-20\n",
                "         }\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, **params)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- with alpha = 1e-20: w_(1, 1)^(2) * b_1 + b_2 is 536.832,298621 (the difference is even closer,\n",
                "# -- not perfectly the same due to rounding)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## More Complex NNs\n",
                "\n",
                "Let's try more complex NN, for example increasing the number of nodes in the only hidden layer, or increasing the number of hidden layers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's build a NN with 2 nodes in the only hidden layer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's build a NN with 2 nodes in the only hidden layer\n",
                "params = {'hidden_layer_sizes': (2, ), 'solver' : 'lbfgs', 'random_state' : numero_di_matricola}\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, **params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's build a NN with 5 nodes in the only hidden layer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's build a NN with 5 nodes in the only hidden layer\n",
                "params = {'hidden_layer_sizes': (5, ), 'solver' : 'lbfgs', 'random_state' : numero_di_matricola}\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, **params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's build a NN with 10 nodes in the only hidden layer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's build a NN with 10 nodes in the only hidden layer\n",
                "params = {'hidden_layer_sizes': (10, ), 'solver' : 'lbfgs', 'random_state' : numero_di_matricola}\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, **params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's build a NN with 100 nodes in the only hidden layer. Note that this is the default!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's build a NN with 100 nodes in the only hidden layer\n",
                "params = {'hidden_layer_sizes': (100, ), 'solver' : 'lbfgs', 'random_state' : numero_di_matricola}\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, print_weights=False, **params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's try 2 layers, 1 node each"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's build a NN with 2 hidden layers each with a node\n",
                "params = {'hidden_layer_sizes': (1, 1), 'solver' : 'lbfgs', 'random_state' : numero_di_matricola}\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, **params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's try 2 layers, 2 nodes each"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's build a NN with 2 hidden layers each with two nodes\n",
                "params = {'hidden_layer_sizes': (2, 2), 'solver' : 'lbfgs', 'random_state' : numero_di_matricola}\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, **params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Try other architectures! "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's build a NN with 2 hidden layers each with 10 nodes\n",
                "params = {'hidden_layer_sizes': (10, 10), 'solver' : 'lbfgs', 'random_state' : numero_di_matricola}\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, **params)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's build a NN with 2 hidden layers each with 100 nodes\n",
                "params = {'hidden_layer_sizes': (100, 100), 'solver' : 'lbfgs', 'random_state' : numero_di_matricola}\n",
                "train_model(X_train_scaled, Y_train, X_val_scaled, Y_val, print_weights=False, **params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "How can we find the best architecture?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### $k$-Fold Cross Validation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's try 5-fold cross-validation with number of nodes in the hidden layer between 1 and 20. Note that we use train and validation data together, since we are doing cross-validation.\n",
                "\n",
                "Note: you can also try to change the maximum amount of iterations to see what happens (see documentation for max_iter parameter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import KFold\n",
                "from itertools import product\n",
                "\n",
                "\n",
                "def k_fold_cross_validation(X_train, Y_train, random_state, num_folds = 5):\n",
                "\n",
                "    # -- grid of hyperparams\n",
                "    param_grid = {'hidden_layer_sizes': [i for i in range(1, 21)],\n",
                "                  'activation': ['relu'],\n",
                "                  'solver': ['lbfgs'],\n",
                "                  'random_state': [random_state],\n",
                "                  'max_iter': [150, 175, 200]\n",
                "                 }\n",
                "\n",
                "    param_list = [\n",
                "    {'hidden_layer_sizes': hls, 'activation': act, 'solver': solv, 'random_state': rs, 'max_iter': mit}\n",
                "    for hls, act, solv, rs, mit in product(\n",
                "        param_grid['hidden_layer_sizes'],\n",
                "        param_grid['activation'],\n",
                "        param_grid['solver'],\n",
                "        param_grid['random_state'],\n",
                "        param_grid['max_iter']\n",
                "    )\n",
                "    ]\n",
                "\n",
                "    err_train_kfold = np.zeros(len(param_list),)\n",
                "    err_val_kfold = np.zeros(len(param_list),)\n",
                "\n",
                "    # print('Params for model selection:', param_list)\n",
                "\n",
                "    kf = KFold(n_splits = num_folds)\n",
                "\n",
                "\n",
                "    # -- perform kfold validation for model selection (k = 5)\n",
                "    for i, params in enumerate(param_list):\n",
                "\n",
                "        print(f'#{i+1}  {params}...')\n",
                "        mlp_model = MLPRegressor(**params)\n",
                "\n",
                "        for train_index, validation_index in kf.split(X_train):\n",
                "\n",
                "            X_train_kfold, X_val_kfold = X_train[train_index], X_train[validation_index]\n",
                "            Y_train_kfold, Y_val_kfold = Y_train[train_index], Y_train[validation_index]\n",
                "\n",
                "            # -- data scaling: standardize features with respect to the current folds\n",
                "            scaler_kfold = preprocessing.StandardScaler().fit(X_train_kfold)\n",
                "            X_train_kfold_scaled = scaler_kfold.transform(X_train_kfold)\n",
                "            X_val_kfold_scaled = scaler_kfold.transform(X_val_kfold)\n",
                "\n",
                "            # -- learn the model using the training data from the k-fold\n",
                "            mlp_model.fit(X_train_kfold_scaled, Y_train_kfold)\n",
                "\n",
                "            # -- incremental mean\n",
                "            err_train_kfold[i] += (1 - mlp_model.score(X_train_kfold_scaled, Y_train_kfold))\n",
                "            err_val_kfold[i] += (1 - mlp_model.score(X_val_kfold_scaled, Y_val_kfold))\n",
                "        print(\"train cv error\", err_train_kfold[i] / num_folds)\n",
                "        print(\"val cv error\", err_val_kfold[i] / num_folds)\n",
                "        print()\n",
                "\n",
                "\n",
                "    # -- compute the mean => estimate of validation losses and errors for each lam\n",
                "    err_train_kfold /= num_folds\n",
                "    err_val_kfold /= num_folds\n",
                "\n",
                "    # -- choose the regularization parameter that minimizes the loss\n",
                "    print('\\n---\\n')\n",
                "    best_param = param_list[np.argmin(err_val_kfold)]\n",
                "    print('Best value of the parameters:', best_param)\n",
                "    print('Min validation error:', np.min(err_val_kfold))\n",
                "\n",
                "    return best_param"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- obtain the best paramaters by running k_fold_cross_validation on training data\n",
                "best_param = k_fold_cross_validation(X_train_scaled, Y_train, random_state = numero_di_matricola)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note that with a smaller number of iterations we had a larger error on training set but a smaller error on validation data -> \"early stopping is a form of regularization\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's train the model with best_param on train and validation\n",
                "final_model = MLPRegressor(**best_param)\n",
                "final_model.fit(X_train_and_val_scaled, Y_train_and_val)\n",
                "training_error = 1.0 - final_model.score(X_train_and_val_scaled, Y_train_and_val)\n",
                "print(\"Training error of best model: \", training_error)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# -- let's compute the test error\n",
                "test_error = 1.0 - final_model.score(X_test_scaled, Y_test)\n",
                "print(\"Test error of best model: \", test_error)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
